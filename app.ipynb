{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faze 1 And 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amirhossein Rezazade / Elham Ghorbani"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "در این بخش ابتدا تمام کتابخانه های مورد نیاز خود را اضافه میکنیم "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T04:41:14.860105Z",
     "start_time": "2021-04-25T04:41:14.854025Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np, hazm, pandas as pd,sys , collections,math\n",
    "from hazm import *\n",
    "import codecs\n",
    "import xml.etree.ElementTree as ET\n",
    "from bplustree import BPlusTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path =\"C:/Users/Asus/Desktop/nlp/PR/\"\n",
    "path =\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A model for reading data\n",
    "کلاس آیتم یک کلاس مدل برای ذخیره اطلاعات لازم و پارس کردن دیتای اصلی میباشد"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Item:\n",
    "   def __init__(self):\n",
    "    self.text = ''\n",
    "    self.date = ''\n",
    "    self.cat = ''\n",
    "    self.titel = ''\n",
    "    self.id = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading XML File and Creating Arry of items\n",
    "در این بخش ابتدا لیستی خالی برای پر کردن دیتا درست میکنیم و قایل دیتای اصلی را باز میکنیم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyData = []\n",
    "tree = ET.parse(path+'data.xml')\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "این بخش با استفاده از تگ های موجود در فایل توشته شده است و به ان صورت توانستیم دیتای اصلی را پارس کرده و در لیست قرار دهیم \n",
    "در همین زمان تمام آیدی ها را خودمان به عدد تبدیل میکنیم تا بتوانیم با آیدی های عددی کار کنیم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "id = 0\n",
    "for child in root: # DOC\n",
    "    myItem = Item()\n",
    "    for child1 in child:  \n",
    "        if child1.tag == \"TEXT\":\n",
    "            myItem.text = child1.text\n",
    "        if child1.tag == \"ISSUE\":\n",
    "            myItem.date = child1.text\n",
    "        if child1.tag == \"TITLE\":\n",
    "            myItem.titel = child1.text\n",
    "        if child1.tag == \"CAT\":\n",
    "            myItem.cat = child1.text\n",
    "        if child1.tag == \"DOCID\":\n",
    "            #myItem.id = child1.text\n",
    "            myItem.id = id\n",
    "            id+=1\n",
    "    MyData.append(myItem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "در اینجا برای مقال زمان مربوط به سند هفتم را چاپ میکنیم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "دوشنبه 11 دي 1385 - سال چهاردهم - شماره4172 - Jan 1, 2007\n"
     ]
    }
   ],
   "source": [
    "print(MyData[7].date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Removable charecters and stop words from file \n",
    "دراین بخش فایلی  به نام کاراکتر های غیر مجاز داریم که باید این کاراکتر ها را حذف کنیم و از آن جایی که هر کاراکتر در خطی ذخیره شده است پس اندیس صفر ام هر خط را خوانده و در لیستی قرار میدهیم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlist = codecs.open(path+\"Removable charecters.txt\", encoding='utf-8').read().split('\\n')\n",
    "# rlist is arry of Removable charecters\n",
    "removeable = [c[0] for c in rlist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "برای مثال کاراکتر 18 ام را چاپ میکنیم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "꧁\n"
     ]
    }
   ],
   "source": [
    "print(removeable[18])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "در اینجا همان عمل را برای کلمات توقف انجام میدهیم و تمام آن ها را بار گیری میکنیم و در نهایت لیستی از آن درست میکنیم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T04:01:41.379366Z",
     "start_time": "2021-04-25T04:01:41.322298Z"
    }
   },
   "outputs": [],
   "source": [
    "nmz = Normalizer()\n",
    "wordTokenizer = WordTokenizer()\n",
    "lemmatizer = Lemmatizer()\n",
    "slist = codecs.open(path+'Stops.txt', encoding='utf-8').read().split('\\n')\n",
    "stops = sorted(list([nmz.normalize(w) for w in slist if w]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "برای مقال کلمه توقف 25 ام را نشان میدهیم "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "آره\n"
     ]
    }
   ],
   "source": [
    "print(stops[25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Normalizer,WordTokenizer and Lemmatizer Class\n",
    "#### we can see usage from this url : https://github.com/sobhe/hazm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "در تابع زیر ما یک متن به ورودی میدهیم و از آن لیستی از کلمات را مییگریم که این کلمات نرمال شده و تمام کلمات توقف از آن حذف گردیده است"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Process(TEXT):        \n",
    "    TEXT = ''.join([c for c in TEXT if c not in removeable])\n",
    "    TEXT = nmz.character_refinement(TEXT) # pack kardan kalamat arabi va adad englisi\n",
    "    TEXT = nmz.affix_spacing(TEXT) # tabdile fasele be nim fasele                 \n",
    "    tokens = wordTokenizer.tokenize(TEXT)\n",
    "    tokens = [lemmatizer.lemmatize(t) for t in tokens if t not in stops]                     \n",
    "    tokens = set(tokens)\n",
    "    tokens = sorted(list(tokens))        \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "برای مقال عبارت زیر را به تابع میدهیم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['بورس', 'سهام', 'پول']\n"
     ]
    }
   ],
   "source": [
    "print(Process('سهام یا بورس و پول'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "در اینجا تمام استاد را پیمایش میکنیم و متن تک تک آن ها را با استفاده از تابع خود به لیتستی از توکن ها تبدیل میکنیم و در مدل جدید خود قرار میدهیم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T04:18:01.152563Z",
     "start_time": "2021-04-25T04:16:31.502981Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "class TokenItem:\n",
    "  def __init__(self):\n",
    "    self.DocId = 0\n",
    "    self.Tokens = []\n",
    "\n",
    "TokenList = []\n",
    "\n",
    "for item in MyData:\n",
    "    t = TokenItem()\n",
    "    t.DocId = item.id\n",
    "    t.Tokens = Process(item.text)\n",
    "    TokenList.append(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "در نهابت لیستی که داریم شامل تمام آیدی ها به همراه توکن های آن هاست"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example\n",
    "چاپ آرایه 15 از توکن لیستمان \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['آذرماه', 'آلات', 'آورد#آور', 'ارزش', 'از\\u200e', 'اساس', 'استدر', 'افت', 'افزایش', 'افزود#افزا', 'الف', 'املاک', 'انبوه', 'اوراق', 'ایجاد', 'ایران', 'ب', 'بازار', 'بازارساز', 'بازیگر', 'بانک', 'بزرگ', 'بلندمدت', 'بهادار', 'بورس', 'بورسهای', 'تاسیس', 'تجهیزات', 'تدریجی', 'تصحیح', 'تصمیم', 'تعادل', 'تعدیل', 'توجه', 'توس', 'تولید', 'جمع', 'جمله', 'حفظ', 'حمایت', 'خاص', 'خروج', 'خرید', 'خریدار', 'خصوصی', 'خیز', 'دادطی', 'داشت#دار', 'درصد', 'دنیا', 'روند', 'زنده', 'زیرمجموعه', 'سال', 'سدید', 'سرمایه', 'سزا', 'سموم', 'سهام', 'سهامدار', 'سهم', 'سود', 'سودآوری', 'سیستم', 'شرکت', 'شیما', 'شیمیایی', 'علف', 'عملکرد', 'غیررسمی', 'فروش', 'فعالیت', 'فلزات', 'قبل', 'لوله', 'ماشین', 'مالکیت', 'مالی', 'متعادل', 'مجموعه', 'محدود', 'محدودی', 'محدودیت', 'محصولات', 'مرور', 'مستغلات', 'منابع', 'موثر', 'موثری', 'نظام', 'نقش', 'نگه', 'وضعیت', 'پارس', 'پاسارگاد', 'پررنگ', 'پول', 'چشمگیر', 'کارگیری', 'کاهش', 'کرد#کن', 'کسب', 'کش', 'کشور', 'کمباین', 'گذاری\\u200cهای', 'گروه', 'گزارش', 'گستر']\n"
     ]
    }
   ],
   "source": [
    "print (TokenList[15].Tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### posting\n",
    " \n",
    "اول امدیم پستینگ را به عنوان دیکشنری  تعریف کردیم ،و تابعی به نام ادداک که دو آرگومان ،توکن و داک آیدی داره را نوشته و پستینگ را به عنوان متغییر سراسری گرفتیم و گفتیم که اگر توکن در پستینگ ما نبود داک آیدی را اضافه کن به پستینگ ما و تابعی به نام اساینمنت  با آرگمان توکن ایتم داریم و با استفاده از کتابخونه پانداس  آمدیم سریس که مشابه ارایه یک بعدی که داده ها را از هر نوعی ذخیره می کند که مقادیر  قایل تغییر اما اندازه غیر قابل تغییر داردبرای  توکن آیتم داک ایدی و توکن  بدست آورده و در آخر اجرا کردیم با لمبداکه همان حلقه فور اما سریع تر ،در نهایت با حلقه دونه دونه کلمات را بگیره و به ما پستینگش را بده .            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Posting = {}\n",
    "def addDoc(token,docID):\n",
    "    global Posting\n",
    "    if(token not in Posting):\n",
    "        Posting[token] = []\n",
    "    Posting[token].append(docID)                               \n",
    "    \n",
    "def Assignment(tokenitem): \n",
    "    pd.Series(tokenitem.Tokens).apply(lambda token: addDoc(token, tokenitem.DocId));        \n",
    "\n",
    "\n",
    "for i in TokenList:\n",
    "    Assignment(i)\n",
    "\n",
    "for v in Posting.values():\n",
    "    v = sorted(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example\n",
    "چاپ  پستینگ کلمه مورد نظر  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 7, 11, 85, 95]\n"
     ]
    }
   ],
   "source": [
    "print(Posting[\"ادب\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### query \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "در این لخش به یک تابع برای پرس و جو تعریف میکنیم که همان تابع اصلی برنامه ماست که سرویس جسجو را به برنمه کلاینت میدهد در این تابع ابتدا یک متن گرفته شده و با همان تابع نرمال کننده به لبستی از توکن ها تبدیل میشود و هر توکن جداگانه پرس وجو میشود\n",
    "در نهایت همه پرس و جو ها با هم اشتراک گرفته میشوند"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Query(Text):\n",
    "    try:\n",
    "        WordTokens = Process(Text)\n",
    "        posting_List = []\n",
    "        for word in WordTokens:\n",
    "            posting = Posting[word]\n",
    "            posting_List.append(posting)\n",
    "\n",
    "        if(len(posting_List) == 0):\n",
    "            return []\n",
    "\n",
    "        FInalPosting = posting_List[0]\n",
    "\n",
    "        for plist in posting_List:\n",
    "            FInalPosting = set(FInalPosting).intersection(plist)\n",
    "            \n",
    "        return sorted(FInalPosting)        \n",
    "    except:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example\n",
    "پستیمگ یک ترم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 21, 54, 86]\n"
     ]
    }
   ],
   "source": [
    "print(Posting[\"پول\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "برای مثال تمام پستینگ های یک عبارت این گونه است"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "بورس : [13, 15, 16, 17, 18]\n",
      "سهام : [13, 14, 15, 16, 17, 18, 53, 91]\n",
      "پول : [15, 21, 54, 86]\n"
     ]
    }
   ],
   "source": [
    "myText = \"سهام یا بورس و پول\"\n",
    "tk = Process(myText)\n",
    "for t in tk:\n",
    "    print(t + \" : \" + str(Posting[t]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "تابع پرس و جوی ما باید اشتراک این سه مجموعه را برگرداند"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15]\n"
     ]
    }
   ],
   "source": [
    "print(Query('سهام یا بورس و پول'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "در انتها سه تایع زیر برای استفاده در رابط کاربری نرم افزار استفاده میگردد\n",
    " اولی برای گرفتن لیست مناسبی از نتیجه پرس و چو و دومی برای گرفتن اطلاعات یک سند به صورت انفرادی\n",
    "سومس هم برای دادن لیست پیشنهادی به کاربر از طریق پستینگ ها"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "تابع پرس چو برای کلاینت"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetDocList(Text):\n",
    "    posintg = Query(Text)\n",
    "    DocList = []\n",
    "    for docId in posintg:\n",
    "        for item in MyData:\n",
    "            if(docId == item.id):\n",
    "                jData = {\n",
    "                    'Id' : item.id,\n",
    "                    'Category' : item.cat,\n",
    "                    'Titel' : item.titel,\n",
    "                    'Text' : item.text[0:20] + \" ...\",\n",
    "                    'Date' : item.date\n",
    "                }\n",
    "                DocList.append(jData)\n",
    "    return DocList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "تابع گرفتن اطلاعات یک سند برای کلاینت"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetDoc(DocId):\n",
    "    for item in MyData:\n",
    "        if(item.id == DocId):\n",
    "            return {\n",
    "                'Id' : item.id,\n",
    "                'Category' : item.cat,\n",
    "                'Titel' : item.titel,\n",
    "                'Text' : item.text,\n",
    "                'Date' : item.date\n",
    "            }\n",
    "    return {\n",
    "            'Id' : DocId,\n",
    "            'Category' : '',\n",
    "            'Titel' : '',\n",
    "            'Text' : '',\n",
    "            'Date' : ''\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "تابع دادن پیشنهاد به کاربر از طریق پستینگ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetSuggestion(Text):\n",
    "    w = Text.split(' ')\n",
    "    last = w[len(w)-1]\n",
    "    index = Text.index(last)\n",
    "    res = []\n",
    "    for i in Posting.keys():\n",
    "        if(i.startswith(last)):\n",
    "            res.append(Text[0:index] + i)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### در هم سازی"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "تایع هش ما یک کلمه میگیرد و یک عدد بین صفر تا عدد مورد نظر را به ما میدهد "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(str,max):\n",
    "    num = hash(str)\n",
    "    return num % max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "برای مثال"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": [
    "print(h(\"hi\",100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "حالا تعداد تمام ترم های موجود در دیکشنری را میبینیم "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4809\n"
     ]
    }
   ],
   "source": [
    "Count = len(Posting.keys())\n",
    "print(Count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "آرایه ای به طول تمام کلمات خود ایجاد میکنیم تا کلمات خود را در آرایه بریزیم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "arr = []\n",
    "for i in range(Count):\n",
    "    arr.append([])\n",
    "\n",
    "\n",
    "for k in Posting.keys():\n",
    "    index = h(k,Count)\n",
    "    arr[index].append(k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "تایع جستجو در این آرابه در هم سازی شده به صورت زیر است"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Find(Word):\n",
    "    find_index = h(Word,Count)\n",
    "    return (Word in arr[find_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "جستحو بسیار سریع"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "my_word = \"یکدست\"\n",
    "\n",
    "print(Find(my_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "تست و ارزیابی"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "میدانیم که بر ای همه کلمات موچود در دیکشنری جا داریم پس در حالت ایده آل نباید جای خالی در آرایه وجود داشته باشد"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  |   1798   : 37.39 %\n",
      "1  |   1727   : 35.91 %\n",
      "2  |   882   : 18.34 %\n",
      "3  |   311   : 6.47 %\n",
      "4  |   72   : 1.5 %\n",
      "5  |   17   : 0.35 %\n",
      "6  |   2   : 0.04 %\n"
     ]
    }
   ],
   "source": [
    "CountLIst = []\n",
    "for x in arr:\n",
    "    CountLIst.append(len(x))\n",
    "\n",
    "Temp = sorted(set(CountLIst))\n",
    "\n",
    "for x in Temp:\n",
    "    print(\n",
    "     str(x) +\n",
    "      \"  |   \" +\n",
    "       str(CountLIst.count(x)) +\n",
    "        \"   : \" +\n",
    "         str(round(CountLIst.count(x) / Count * 100,2)) + \" %\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "مثال"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "my_word = \"سلام\"\n",
    "\n",
    "find_index = h(my_word,Count)\n",
    "\n",
    "print(arr[find_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "درخت"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.programmersought.com/article/77574639100/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import B_Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "برای پرس جوی کلمات * دار، باید تابعی داشته باشیم که عبارت بعد از کلمه را بدهد"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "مثلا عبارت سهان بعد از کلمه سهام است"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "سهان\n"
     ]
    }
   ],
   "source": [
    "def GetNextWord(Word):\n",
    "    last = Word[-1]\n",
    "    x = chr(ord(last) + 1)\n",
    "    return Word[0:len(Word)-1] + x\n",
    "\n",
    "print(GetNextWord(\"سهام\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "برای این که مقدار و پستیگ های خود را در درخت قرار دهیم کلاس زیر را ایجاد میکنیم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PData(object):\n",
    "    def __init__(self, v, p):\n",
    "        self.Term = v\n",
    "        self.Term_Posting = p\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.Term\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.Term\n",
    "\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if type(other) != PData:\n",
    "            return other == self.Term\n",
    "        return other.Term == self.Term\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        if type(other) != PData:\n",
    "            return other > self.Term\n",
    "        return other.Term > self.Term\n",
    "\n",
    "    def __le__(self, other):\n",
    "        if type(other) != PData:\n",
    "            return other <= self.Term\n",
    "        return other.Term <= self.Term\n",
    "\n",
    "    def __gt__(self, other):\n",
    "        if type(other) != PData:\n",
    "            return other < self.Term\n",
    "        return self.Term > other.Term\n",
    "\n",
    "    def __ge__(self, other):\n",
    "        if type(other) != PData:\n",
    "            return other <= self.Term\n",
    "        return self.Term >= other.Term\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        if type(other) != PData:\n",
    "            return other != self.Term\n",
    "        return self.Term != other.Term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "تست کلاس"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "v1 = PData(\"a\",[])\n",
    "v2 = PData(\"a\",[])\n",
    "\n",
    "print(v1)\n",
    "print (v1>v2)\n",
    "print(v1<v2)\n",
    "print(v1==v2)\n",
    "print(v1==\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "حالا باید تمام پستیگ خود را به درخت تبدیل کنیم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "scala = 2\n",
    "\n",
    "\n",
    "forward = B_Tree.BTree(scala)               \n",
    "backward = B_Tree.BTree(scala)\n",
    "\n",
    "for term in Posting.keys():\n",
    "    posting = Posting[term]\n",
    "    forward.insert (PData(term      , posting))       \n",
    "    backward.insert(PData(term[::-1], posting))                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "پیدا کردن کلمه ای مشخص"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "سهام [13, 14, 15, 16, 17, 18, 53, 91]\n"
     ]
    }
   ],
   "source": [
    "s = \"سهام\"\n",
    "res = forward.search(s)\n",
    "\n",
    "print(res.Term + \" \"  + str(res.Term_Posting))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "جستجو کلمه پیشوندی"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "باب\n",
      "بابا\n",
      "بابک\n",
      "باتجربه‌ترین‌های\n",
      "باجه\n",
      "باخت#باز\n",
      "باخترینه\n",
      "باران\n",
      "بارز\n",
      "بارسلون\n",
      "بارسلونا\n",
      "بارقه\n",
      "بارور\n",
      "باریک\n",
      "باریکه\n",
      "بازارارزش\n",
      "بازبینی\n",
      "بازجویی\n",
      "بازده\n",
      "بازدید\n",
      "بازرسی\n",
      "بازشدن\n",
      "بازماندگان\n",
      "بازنده\n",
      "بازنشسته\n",
      "بازنشستگی\n",
      "بازو\n",
      "بازپرداخت\n",
      "بازگردیم\n",
      "بازگشتن\n",
      "بازگشتی\n",
      "بازگفتی\n",
      "بازگو\n",
      "بازیکن\n",
      "بازیکنانش\n",
      "باستان\n",
      "باستانی\n",
      "باسک\n",
      "باشداز\n",
      "باشددر\n",
      "باشکوه\n",
      "باشیمبعد\n",
      "باطله\n",
      "باغ\n",
      "باغبان\n",
      "باقرعاظهار\n",
      "بال\n",
      "بالاستتعرفه\n",
      "بالقوه\n",
      "بالینیزنان\n",
      "بامانیز\n",
      "بامدادان\n",
      "بامعنا\n",
      "بانو\n",
      "باهنر\n",
      "باورناپذیر\n",
      "باکس\n",
      "باید\n",
      "ببر\n",
      "ببرد\n",
      "ببری\n",
      "ببینی\n",
      "بتوزند\n",
      "بتون\n",
      "بحران\n",
      "بختیار\n",
      "بخشش\n",
      "بخشید#بخش\n",
      "بد\n",
      "بدان\n",
      "بدخواه\n",
      "بدل\n",
      "بدلیل\n",
      "بدهکار\n",
      "بدکنش\n",
      "بدیل\n",
      "بدیهی\n",
      "برآنیم\n",
      "برآورده\n",
      "برابرآثار\n",
      "برادر\n",
      "برافروزند\n",
      "برانگیخت\n",
      "برایتان\n",
      "بربافته‌اند\n",
      "برتر\n",
      "برترین‌های\n",
      "برجسته\n",
      "برخواهند\n",
      "برخورد\n",
      "برد\n",
      "برد#بر\n",
      "بردار\n",
      "برداشت\n",
      "بردن\n",
      "بردگی\n",
      "بردیاب\n",
      "بررسد\n",
      "برزان\n",
      "برساخته‌اند\n",
      "برسانددر\n",
      "برشمارم\n",
      "برطرف\n",
      "برف\n",
      "برقرار\n",
      "برقراری\n",
      "برقی‌ها\n",
      "برمی\n",
      "برنج\n",
      "برهانی\n",
      "برودمنچستر\n",
      "برون\n",
      "برپایه\n",
      "برپایی\n",
      "برکشیدن\n",
      "برکنار\n",
      "برگرداندن\n",
      "برگردانده\n",
      "برگردم\n",
      "برگزارخواهند\n",
      "برگزیدند\n",
      "برگزیده\n",
      "بریتانیا\n",
      "بزرگ\n",
      "بزرگراه\n",
      "بست#بند\n",
      "بسترسازی\n",
      "بسته\n",
      "بستگی\n",
      "بسر\n",
      "بسنجد\n",
      "بسکتبال\n",
      "بشرطها\n",
      "بشریت\n",
      "بعث\n",
      "بعدشنبههم\n",
      "بغداد\n",
      "بغدادخبر\n",
      "بقیه\n",
      "بلا\n",
      "بلاروس\n",
      "بلد\n",
      "بلر\n",
      "بلغارستان\n",
      "بلندا\n",
      "بلندالبته\n",
      "بلندنظر\n",
      "بلندو\n",
      "بلو\n",
      "بلورکوارتز\n",
      "بلوچ\n",
      "بلوچستان\n",
      "بمب\n",
      "بمکد\n",
      "بن\n",
      "بند\n",
      "بندرعباس\n",
      "بندی‌ها\n",
      "بنیاد\n",
      "بنیامین\n",
      "بها\n",
      "بهاالدین\n",
      "بهار\n",
      "بهارستان\n",
      "بهانه\n",
      "بهبود\n",
      "بهداشت\n",
      "بهرام\n",
      "بهشتی\n",
      "بهنام\n",
      "بو\n",
      "بوجود\n",
      "بودجه\n",
      "بودن\n",
      "بودندم\n",
      "بورس\n",
      "بورنئو\n",
      "بوستان\n",
      "بوعلی\n",
      "بوق\n",
      "بولدوزر\n",
      "بولدوزرهای\n",
      "بومی\n",
      "بوکانگاراگل\n",
      "بویایی\n",
      "بچرخانند\n",
      "بچرخی\n",
      "بچینند\n",
      "بکارگیری\n",
      "بکوبند\n",
      "بگوئید\n",
      "بیات\n",
      "بیان\n",
      "بیدار\n",
      "بیرو\n",
      "بیروت\n",
      "بیستم\n",
      "بیشینه\n",
      "بیفتند\n",
      "بیفزاید\n",
      "بیم\n",
      "بیمارانی\n",
      "بیماری‌های\n",
      "بیمناک\n",
      "بیمه‌گر\n",
      "بیندازیم\n",
      "بیننده\n",
      "بینندگان\n",
      "بیهقی\n",
      "بیوتکنولوژی\n",
      "بیگانه\n"
     ]
    }
   ],
   "source": [
    "s = \"ب\"\n",
    "Word_Next = GetNextWord(s)\n",
    "res = forward.GetValue(s,Word_Next)\n",
    "\n",
    "for i in res:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "جستجو کلمه پسوندی"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "اعتبار\n",
      "اخبار\n",
      "دربار\n",
      "تأسفبار\n",
      "اسفبار\n",
      "انبار\n"
     ]
    }
   ],
   "source": [
    "s = \"بار\"\n",
    "s = s[::-1]\n",
    "w = GetNextWord(s)\n",
    "res = backward.GetValue(s,w)\n",
    "\n",
    "for i in res:\n",
    "    print(i.Term[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "جستجو میانوندی و اشتراک گیری میان دو جواب درخت ها"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ساختار\n",
      "سازگار\n",
      "سیگار\n"
     ]
    }
   ],
   "source": [
    "s = \"س\"\n",
    "e = \"ار\"\n",
    "\n",
    "w = GetNextWord(s)\n",
    "fres = forward.GetValue(s,w)\n",
    "e = e[::-1]\n",
    "w = GetNextWord(e)\n",
    "bres = backward.GetValue(e,w)\n",
    "\n",
    "for i in fres:\n",
    "    for j in bres:\n",
    "        if i.Term == j.Term[::-1]:\n",
    "            print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "لیست کلمات فارسی"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "در قایل زیر مجموعه ای از کلمات فارسی قرار گرفته است"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "Word_as_Text = codecs.open(path+'Words.txt', encoding='utf-8').read()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetWords(TEXT):        \n",
    "    TEXT = ''.join([c for c in TEXT if c not in removeable])\n",
    "    TEXT = nmz.character_refinement(TEXT) # pack kardan kalamat arabi va adad englisi                \n",
    "    tokens = wordTokenizer.tokenize(TEXT)                  \n",
    "    tokens = set(tokens)\n",
    "    tokens = sorted(list(tokens))        \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "با تابع بالا کلمات درون فایل متنی را استخراج میکنیم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "Words = GetWords(Word_as_Text) + stops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "تعداد همه کلمات"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31458\n"
     ]
    }
   ],
   "source": [
    "print(len(Words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Levenshtein\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "حداقل فاصله ویرایش \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "برکرفته از https://python-course.eu/applications-python/levenshtein-distance.php"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "حداقل فاصله ویرایش بین دو رشته، حداقل تعداد عملیات ویرایش مورد نیاز برای تبدیل یک رشته به رشته دیگر است. عملیات ویرایش می تواند شامل درج، حذف و جایگزینی باشد."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "تابع پایتون زیر فاصله لوناشتاین را پیاده سازی می کند:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_levenshtein(s, t, print_matrix = False):\n",
    "    costs=(1, 1, 1)\n",
    "    rows = len(s)+1\n",
    "    cols = len(t)+1\n",
    "    deletes, inserts, substitutes = costs\n",
    "    \n",
    "    dist = [[0 for x in range(cols)] for x in range(rows)]\n",
    "\n",
    "    # source prefixes can be transformed into empty strings \n",
    "    # by deletions:\n",
    "    for row in range(1, rows):\n",
    "        dist[row][0] = row * deletes\n",
    "\n",
    "    # target prefixes can be created from an empty source string\n",
    "    # by inserting the characters\n",
    "    for col in range(1, cols):\n",
    "        dist[0][col] = col * inserts\n",
    "        \n",
    "    for col in range(1, cols):\n",
    "        for row in range(1, rows):\n",
    "            if s[row-1] == t[col-1]:\n",
    "                cost = 0\n",
    "            else:\n",
    "                cost = substitutes\n",
    "            dist[row][col] = min(dist[row-1][col] + deletes,\n",
    "                                 dist[row][col-1] + inserts,\n",
    "                                 dist[row-1][col-1] + cost) # substitution\n",
    "    if(print_matrix):\n",
    "        for r in range(rows):\n",
    "            print(dist[r])\n",
    "    \n",
    " \n",
    "    return dist[row][col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "مثال"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3]\n",
      "[1, 1, 2, 3]\n",
      "[2, 2, 2, 3]\n",
      "[3, 3, 3, 3]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(iterative_levenshtein(\"abc\", \"xyz\",True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "تابع زیر یک کلمه گرفته و نزدیک ترین پیشنهاد را برمیگرداند"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetTrueWord(token):\n",
    "    min = 999999\n",
    "    min_word = \"\"\n",
    "    for item in Words:\n",
    "        d = iterative_levenshtein(token, item)\n",
    "        if(min > d):\n",
    "            min = d\n",
    "            min_word = item\n",
    "    return min_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "مثال"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "جزو\n"
     ]
    }
   ],
   "source": [
    "print(GetTrueWord(\"سزو\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "تابع زیر یک عبارت را گرفته و عبارت احتمالی درست را برمیگرداند"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModifyText(Text):\n",
    "    tokens = Text.split(' ')\n",
    "    output = \"\"\n",
    "    for t in tokens:\n",
    "        ct = GetTrueWord(t)\n",
    "        output += ct + \" \"\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "مثال"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "سهام و بورس \n"
     ]
    }
   ],
   "source": [
    "myText = \"سهامم و بوورس\"\n",
    "print(ModifyText(myText))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "در نهایت تابع زیر با ترکیب تمامی روش ها یک پرس و جو انجام میدهد"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Query_2(Text):\n",
    "    fixed_Text = ModifyText(Text)\n",
    "    return Query(fixed_Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13, 15, 16, 17, 18]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myText = \"سهامم و بوورس\"\n",
    "Query_2(myText)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
